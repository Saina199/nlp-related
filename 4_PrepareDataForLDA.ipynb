{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 're', 'edu', 'use','need','away','also','come','go',\n",
    "                   'take','get','sure','want','example','include','first','second','next','may','make'])\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/trainData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>summaryLen</th>\n",
       "      <th>textLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make a stencil of your design. test your squee...</td>\n",
       "      <td>for this you will need your original design ma...</td>\n",
       "      <td>143</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>write down the problem. subtract the second ex...</td>\n",
       "      <td>the most simple version of this problem will b...</td>\n",
       "      <td>270</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>download the birth certificate order form. fil...</td>\n",
       "      <td>locate the vital records request for copy of b...</td>\n",
       "      <td>276</td>\n",
       "      <td>2538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  make a stencil of your design. test your squee...   \n",
       "1  write down the problem. subtract the second ex...   \n",
       "2  download the birth certificate order form. fil...   \n",
       "\n",
       "                                                text  summaryLen  textLen  \n",
       "0  for this you will need your original design ma...         143     1442  \n",
       "1  the most simple version of this problem will b...         270     1852  \n",
       "2  locate the vital records request for copy of b...         276     2538  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDoc(doc):  \n",
    "    docy = \" \".join([wrd for wrd in simple_preprocess(doc) if wrd not in stop_words])\n",
    "    return [token.lemma_ for token in nlp(docy) if \n",
    "            (token.lemma_  not in stop_words) & (token.pos_ in ['NOUN', 'ADJ'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 2s, sys: 1min 15s, total: 55min 18s\n",
      "Wall time: 29min 14s\n"
     ]
    }
   ],
   "source": [
    "%time docs = data['text'].apply(lambda x: prepareDoc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/tokenizedTextNoun','wb') as f:\n",
    "    pickle.dump(list(docs),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['you', 'be'], ['need', 'also']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
